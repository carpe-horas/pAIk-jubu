# pip install -r requirements.txt
# streamlit run 03-test-streamlit-app.py

import os
import streamlit as st
from dotenv import load_dotenv
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI

from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_community.llms import OpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

import speech_recognition as sr
from gtts import gTTS
from io import BytesIO
import base64

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="pAIk ì£¼ë¶€ ìš”ë¦¬ ë¹„ì„œ", layout="centered", initial_sidebar_state="collapsed")

# Streamlit UIë¥¼ ì»¤ìŠ¤í…€í•˜ê¸° ìœ„í•´ HTMLê³¼ CSS ì‚¬ìš©
st.markdown(
    """
    <style>
    /* í˜ì´ì§€ ì „ì²´ ë°°ê²½ ìƒ‰ìƒ */
    .main {
        background-color: black;
    }

    /* ì…ë ¥ì°½ê³¼ ë²„íŠ¼ì„ ë‚˜ë€íˆ ë¶™ì´ê¸° ìœ„í•œ ìŠ¤íƒ€ì¼ */
    .input-container {
        display: flex;
        justify-content: flex-start;  /* ë²„íŠ¼ê³¼ ì…ë ¥ì°½ ì •ë ¬ */
        align-items: center; /* ê°€ìš´ë° ì •ë ¬ */
    }

    /* í…ìŠ¤íŠ¸ ìƒ‰ìƒ */
    .stTextInput, .stButton, .stAlert, .stMarkdown {
        color: white !important;
    }

    /* ë²„íŠ¼ ìƒ‰ìƒ ë³€ê²½ */
    .stButton button {
        background-color: #444;
        color: white;
        border-radius: 5px;
        height: 45px;  /* ë²„íŠ¼ ë†’ì´ ì„¤ì • */
        width: auto;  /* ë²„íŠ¼ì˜ ë„ˆë¹„ë¥¼ ìë™ìœ¼ë¡œ ì„¤ì • */
        font-size: 16px;
        margin: 5px;  /* ë²„íŠ¼ ê°„ì˜ ê°„ê²© ì¶”ê°€ */
        margin-top: 25px; /* ë²„íŠ¼ì„ ì•½ê°„ ì•„ë˜ë¡œ ì´ë™ */
    }

    /* í…ìŠ¤íŠ¸ ì…ë ¥ ìƒì ë°°ê²½ ë° í…ìŠ¤íŠ¸ ìƒ‰ìƒ */
    .stTextInput input {
        background-color: #333;
        color: white;
        height: 50px;
        margin-right: 5px; /* ì…ë ¥ì°½ ì˜¤ë¥¸ìª½ ì—¬ë°± ì¡°ì • */
    }

    /* í˜ì´ì§€ ì œëª© ìƒ‰ìƒ ë³€ê²½ */
    h1 {
        color: #FFD700 !important; 
    }

    /* ë§í’ì„  ìŠ¤íƒ€ì¼ */
    .chat-bubble {
        max-width: 60%;
        padding: 10px;
        border-radius: 15px;
        margin-bottom: 10px;
        word-wrap: break-word;
        position: relative;
        display: inline-block;
    }

    /* ì‚¬ìš©ì ë§í’ì„  */
    .user-bubble {
        background-color: #f0edc5;
        color: #2e2c11;
        align-self: flex-end; /* ì˜¤ë¥¸ìª½ ì •ë ¬ */
    }

    /* ì‚¬ìš©ì ë§í’ì„  ê¼¬ë¦¬ */
    .user-bubble::after {
        content: "";
        position: absolute;
        bottom: 0;
        right: -10px;
        width: 0;
        height: 0;
        border-left: 10px solid #f0edc5;
        border-top: 10px solid transparent;
        border-bottom: 10px solid transparent;
    }

    /* AI ë§í’ì„  */
    .assistant-bubble {
        background-color: #e4e6eb;
        color: black;
        align-self: flex-start; /* ì™¼ìª½ ì •ë ¬ */
    }

    /* AI ë§í’ì„  ê¼¬ë¦¬ */
    .assistant-bubble::after {
        content: "";
        position: absolute;
        bottom: 0;
        left: -10px;
        width: 0;
        height: 0;
        border-right: 10px solid #e4e6eb;
        border-top: 10px solid transparent;
        border-bottom: 10px solid transparent;
    }

    /* ì±„íŒ… ì˜ì—­ ë ˆì´ì•„ì›ƒ ì„¤ì • */
    .chat-container {
        display: flex;
        flex-direction: column;
        margin: 0px 0;
    }

    /* ìŠ¤í¬ë¡¤ë°” ìƒ‰ìƒ */
    ::-webkit-scrollbar {
        width: 10px;
    }
    ::-webkit-scrollbar-track {
        background: #333;
    }
    ::-webkit-scrollbar-thumb {
        background: #888;
    }
    ::-webkit-scrollbar-thumb:hover {
        background: #555;
    }
    </style>
    """, 
    unsafe_allow_html=True
)


st.markdown("<h1>pAIk ì£¼ë¶€ ìš”ë¦¬ ë¹„ì„œ</h1>", unsafe_allow_html=True)

# ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰í•  ë•Œ ì´ ì‹¤í–‰íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ë””ë ‰í† ë¦¬ì— .env ë¼ëŠ” ì´ë¦„ì˜ íŒŒì¼ì„ ìƒì„±í•˜ì—¬ ChatGPT ì‚¬ìš©ì„ ìœ„í•œ API KEYì™€ ê°™ì€
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ì„ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.
# .env íŒŒì¼ ë‚´ìš©ì€ ì•„ë˜ì™€ ê°™ì´ ë¯¸ë¦¬ ì •ì˜í•´ ë‘ì–´ì•¼ í•©ë‹ˆë‹¤. 
# OPENAI_API_KEY="sk-proj-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"
#
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI API í‚¤ ë¡œë“œ
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()  # API í‚¤ê°€ ì—†ìœ¼ë©´ ë” ì´ìƒ ì‹¤í–‰ë˜ì§€ ì•Šë„ë¡ í•¨


# FAISS ë²¡í„° ìŠ¤í† ì–´ëŠ” 24-vectorstore-save.ipynbì—ì„œ ì €ì¥í•œ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
# ì´ íŒŒì¼ì´ ì¡´ì¬í•˜ê³  ìˆëŠ” ë””ë ‰í† ë¦¬ í•˜ìœ„ì— db/faiss ë””ë ‰í† ë¦¬ì— ë²¡í„° ìŠ¤í† ì–´ DB íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤

# FAISS ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹œ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ë©”ì‹œì§€ ìˆ˜ì •
def load_faiss():
    # ë¡œë”© ì¤‘ ë©”ì‹œì§€ë¥¼ ìœ„í•œ placeholder ìƒì„±
    loading_message = st.empty()
    
    # ë¡œë”© ì¤‘ ë©”ì‹œì§€ í‘œì‹œ
    loading_message.markdown('<div style="text-align: left; font-size: 18px; color: #FFFFFF;">AI ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³  ìˆìŠµë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš” ğŸ˜Š</div>', unsafe_allow_html=True)
    
    # ì‹¤ì œ FAISS ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
    embeddings = OpenAIEmbeddings(openai_api_key=api_key)
    vector_store = FAISS.load_local('./db/faiss', OpenAIEmbeddings(), allow_dangerous_deserialization=True)

    # ë¡œë“œ ì™„ë£Œ í›„ ê¸°ì¡´ ë¡œë”© ë©”ì‹œì§€ë¥¼ ì„±ê³µ ë©”ì‹œì§€ë¡œ ë³€ê²½
    loading_message.markdown('<div style="text-align: left; font-size: 18px; color: #FFFFFF;">AI ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!</div>', unsafe_allow_html=True)
    
    return vector_store

# Google Speech Recognitionì„ ì‚¬ìš©í•œ ìŒì„± ì¸ì‹ í•¨ìˆ˜
def recognize_speech():
    r = sr.Recognizer()
    
    # ë§ˆì´í¬ë¡œë¶€í„° ìŒì„± ì…ë ¥ ë°›ê¸°
    with sr.Microphone() as source:
        st.write("ìŒì„± ì¸ì‹ì¤‘.....")
        r.adjust_for_ambient_noise(source)  # ì£¼ë³€ ì†ŒìŒ ì¡°ì ˆ
        audio = r.listen(source)  # ìŒì„± ì…ë ¥ ë°›ê¸°
    
    try:
        # Google Speech Recognitionì„ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        text = r.recognize_google(audio, language='ko-KR')
        st.write("ì¸ì‹ ì™„ë£Œ")
        return text
    except sr.UnknownValueError:
        st.write("ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return ""
    except sr.RequestError as e:
        st.write(f"Google Speech Recognition ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""

# í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¬ìƒí•˜ëŠ” í•¨ìˆ˜ (gTTS ì‚¬ìš©)
def speak_text_gtts(text):
    tts = gTTS(text=text, lang='ko')
    mp3_fp = BytesIO()
    tts.write_to_fp(mp3_fp)
    mp3_fp.seek(0)

    # ìŒì„±ì„ ë¸Œë¼ìš°ì €ì—ì„œ ì¬ìƒí•˜ê¸° ìœ„í•´ base64ë¡œ ì¸ì½”ë”©
    audio_data = base64.b64encode(mp3_fp.read()).decode("utf-8")
    audio_html = f'<audio autoplay="true" controls><source src="data:audio/mp3;base64,{audio_data}" type="audio/mp3"></audio>'
    
    st.markdown(audio_html, unsafe_allow_html=True)

# ì±„íŒ… ë©”ì‹œì§€ë¥¼ session_stateì— ì €ì¥í•˜ì—¬ ë©”ëª¨ë¦¬ ê¸°ëŠ¥ êµ¬í˜„
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

# ì±„íŒ… ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ë§ (ë§í’ì„  ëª¨ì–‘ ì ìš©)
def display_chat_message(role, message, index=None):
    if role == "user":
        st.markdown(f"""
            <div class="chat-bubble user-bubble">
                ğŸ§‘ {message}
            </div>
        """, unsafe_allow_html=True)
    elif role == "assistant":
        st.markdown(f"""
            <div class="chat-bubble assistant-bubble">
                ğŸ¥£ {message}
            </div>
        """, unsafe_allow_html=True)
        
        # ê³ ìœ í•œ í‚¤ ìƒì„±: index, messageì˜ í•´ì‹œê°’ ì‚¬ìš©
        if index is not None:
            unique_key = f"listen_button_{index}_{hash(message)}"
            if st.button("ğŸ”Š ë“£ê¸°", key=unique_key):
                speak_text_gtts(message)


# ì±—ë´‡ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶œë ¥ í•¨ìˆ˜
def display_chat_history():
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    for i, entry in enumerate(st.session_state["chat_history"]):
        display_chat_message(entry["role"], entry["message"], index=i if entry["role"] == "assistant" else None)
    st.markdown('</div>', unsafe_allow_html=True)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜
def process_user_input(query, vector_store):
    if not query:
        st.markdown('<div class="warning-text">ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.</div>', unsafe_allow_html=True)
        return

    # ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ê°€
    if not any(entry['message'] == query and entry['role'] == "user" for entry in st.session_state["chat_history"]):
        st.session_state["chat_history"].append({"role": "user", "message": query})

        
    from langchain_core.prompts import PromptTemplate
    prompt = PromptTemplate.from_template(
        """ë‹¹ì‹ ì€ ì§ˆë¬¸-ë‹µë³€(Question-Answering)ì„ ìˆ˜í–‰í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
        ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ ë¬¸ë§¥(context) ì—ì„œ ì£¼ì–´ì§„ ì§ˆë¬¸(question) ì— ë‹µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
        ê²€ìƒ‰ëœ ë‹¤ìŒ ë¬¸ë§¥(context) ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸(question) ì— ë‹µí•˜ì„¸ìš”. 
        í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.

#Question:
{question}

#Context:
{context}

#Answer:"""
    )
    

    ###############
    # ë‹µë³€ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë ¤ì„œ í…ŒìŠ¤íŠ¸ì‹œ ì‚¬ìš©í•œ openapi
    # from langchain.chat_models import ChatOpenAI 

    # llm = ChatOpenAI(openai_api_key=api_key, temperature=0.5)
    # retriever = vector_store.as_retriever()
    # rag_chain = ({"context": retriever, "question": RunnablePassthrough()} | prompt | llm | StrOutputParser())
    # result = rag_chain.invoke(query)
    ################


    from langchain_community.chat_models import ChatOllama
    from langchain_core.output_parsers import StrOutputParser
    from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
    from langchain_core.callbacks.manager import CallbackManager

    llm = ChatOllama(model="llama2:7b", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]))
    retriever = vector_store.as_retriever()
    rag_chain = ({"context": retriever, "question": RunnablePassthrough()} | prompt | llm | StrOutputParser())
    result = rag_chain.invoke(query)

    # ì¤‘ë³µëœ ë‹µë³€ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸ í›„ ì¶”ê°€
    if not any(entry['message'] == result and entry['role'] == "assistant" for entry in st.session_state["chat_history"]):
        st.session_state["chat_history"].append({"role": "assistant", "message": result})


    # ì‚¬ìš©ì ë° AI ì‘ë‹µ ë©”ì‹œì§€ í‘œì‹œ
    display_chat_history()

# ë²¡í„° ìŠ¤í† ì–´ ì„¤ì •
vector_store = load_faiss()

st.markdown('<div style="text-align: left; font-size: 18px; color: #FFD7;">ì €ëŠ” ìš”ë¦¬ë¥¼ ë„ì™€ ë“œë¦¬ëŠ” ìš”ë¦¬ì‚¬ ë¹„ì„œì…ë‹ˆë‹¤.</div>', unsafe_allow_html=True)

st.markdown('<div style="text-align: left; font-size: 18px; color: #FFD700;">ê¶ê¸ˆí•œ ìš”ë¦¬ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”.</div>', unsafe_allow_html=True)

# ì…ë ¥ì°½ê³¼ ë²„íŠ¼ì„ ë‚˜ë€íˆ ë°°ì¹˜
col1, col2, col3 = st.columns([3, 1, 1])  

with col1:
    user_input = st.text_input("")

with col2:
    submit_button = st.button("ì§ˆë¬¸ í•˜ê¸°")

with col3:
    speech_button = st.button("ğŸ¤ ìŒì„± ì§ˆë¬¸")

# ë²„íŠ¼ ë™ì‘ ì²˜ë¦¬
if submit_button:
    process_user_input(user_input, vector_store)

if speech_button:
    user_input = recognize_speech()
    if user_input:
        process_user_input(user_input, vector_store)

# ì±—ë´‡ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
display_chat_history()
