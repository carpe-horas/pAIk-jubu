# pip install -r requirements.txt
# streamlit run 06-test-streamlit-app.py
# css - ì• ë‹ˆë©”ì´ì…˜ ì ìš©

import os
import streamlit as st
import time
from dotenv import load_dotenv
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI

from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_community.chat_models import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

import speech_recognition as sr
from gtts import gTTS
from io import BytesIO
import base64

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="pAIk ì£¼ë¶€ ìš”ë¦¬ ë¹„ì„œ", layout="centered", initial_sidebar_state="collapsed")

# Streamlit UIë¥¼ ì»¤ìŠ¤í…€í•˜ê¸° ìœ„í•´ HTMLê³¼ CSS ì‚¬ìš©
st.markdown(
    """
    <link href="https://fonts.googleapis.com/css2?family=Jua&display=swap" rel="stylesheet">

    <style>
    /* í˜ì´ì§€ ì „ì²´ ë°°ê²½ ìƒ‰ìƒ */
    .main {
        background-color: #FFF8E1;  
    }

    /* AI ëª¨ë¸ ë¡œë“œ í…ìŠ¤íŠ¸ */
    .info-text {
        color: #FF8C69;  
        font-size: 20px;
        margin-bottom: 15px;
        text-align: center;
        font-family: 'Jua', sans-serif; 
        opacity: 1;
        animation: fadeOut 5s forwards; /* 5ì´ˆ ë™ì•ˆ í‘œì‹œ í›„ ì‚¬ë¼ì§€ëŠ” ì• ë‹ˆë©”ì´ì…˜ */
    }

     /* ì• ë‹ˆë©”ì´ì…˜ ì •ì˜ */
    @keyframes fadeOut {
        0% {
            opacity: 1; /* ì²˜ìŒì—ëŠ” ì™„ì „íˆ ë³´ì„ */
        }
        80% {
            opacity: 1; /* 4ì´ˆ ë™ì•ˆ ìœ ì§€ */
        }
        100% {
            opacity: 0; /* 5ì´ˆ í›„ì— ì™„ì „íˆ ì‚¬ë¼ì§ */
        }
    }

    /*ì¸í’‹ì°½ ìœ„ í…ìŠ¤íŠ¸*/
    .question-text{
        color: #FF7043;  
        font-size: 20px;
        margin-top: 5px;
        margin-bottom: 2px;
        text-align: center;
        font-family: 'Jua', sans-serif; 
    }

    /* í˜ì´ì§€ ì œëª© ìŠ¤íƒ€ì¼ */
    h1 {
        color: #FF5722;  
        text-align: center;
        font-family: 'Jua', sans-serif; 
        font-size: 40px;  
        font-weight: bold;  
        margin-bottom: 40px;
        animation: glow 1.3s ease-in-out infinite alternate; /* ì• ë‹ˆë©”ì´ì…˜ ì ìš© */
    }

    /* ê¸€ìì— ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼ ì¶”ê°€ */
    @keyframes glow {
        from {
            text-shadow: 0 0 10px #FF7043, 0 0 20px #FF7043, 0 0 30px #FF7043;
            color: #FF5722;
        }
        to {
            text-shadow: 0 0 20px #FF8C69, 0 0 30px #FF8C69, 0 0 40px #FF8C69;
            color: #FF8C69;
        }
    }

    /* ì±„íŒ… ì»¨í…Œì´ë„ˆ */
    .chat-container {
        display: flex;
        flex-direction: column;
        width: 100%;
        margin-top: 20px;
    }

    /* ë§í’ì„  ê³µí†µ ìŠ¤íƒ€ì¼ */
    .chat-bubble {
        padding: 15px;
        border-radius: 15px;
        margin-bottom: 10px;
        word-wrap: break-word;
        position: relative;
        display: inline-block;
        font-family: 'Jua', sans-serif; 
        font-size: 16px;
        color: #5A3D05;
        line-height: 1.5;
        max-width: 60%;  
        box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.1);  /* ë¶€ë“œëŸ¬ìš´ ê·¸ë¦¼ì */
    }

    /* ì‚¬ìš©ì ë©”ì‹œì§€ (ì˜¤ë¥¸ìª½ ì •ë ¬) */
    .user-bubble {
        background-color: #F7E269;  
        color: #822903;
        float: right;  /* ë§í’ì„ ì„ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ë°°ì¹˜ */
        border-radius: 15px 15px 0px 15px;  /* ë§í’ì„  ëª¨ì„œë¦¬ */
        text-align: left;
        width: auto;  
        max-width: 60%;  
        margin-top: 10px;
        margin-right: 20px;  
    }

    /* ì‚¬ìš©ì ë§í’ì„  ê¼¬ë¦¬ */
    .user-bubble::after {
        content: "";
        position: absolute;
        bottom: 0;
        right: -10px;
        width: 0;
        height: 0;
        border-left: 10px solid #F7E269;
        border-top: 10px solid transparent;
        border-bottom: 10px solid transparent;
    }

    /* AI ë©”ì‹œì§€ (ì™¼ìª½ ì •ë ¬) */
    .assistant-bubble {
        background-color: #FFC044;  
        color: #822903;
        float: left;  
        border-radius: 15px 15px 15px 0px;
        text-align: left;
        width: auto;  
        max-width: 60%;  
        margin-bottom: -25px;
    }

    /* AI ë§í’ì„  ê¼¬ë¦¬ */
    .assistant-bubble::after {
        content: "";
        position: absolute;
        bottom: 0;
        left: -10px;
        width: 0;
        height: 0;
        border-right: 10px solid #FFC044;
        border-top: 10px solid transparent;
        border-bottom: 10px solid transparent;
    }

    /* ì…ë ¥ì°½ê³¼ ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stTextInput input {
        background-color: #FFF3E0;  
        color: #822903;
        border-radius: 10px;
        border: 1px solid #FF7043;
        padding: 10px;
    }

    stTextInput input:hover {
        background-color: #F4834F;
        color: #f5c4b8; 
    }

    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton button {
        background-color: #FF7043;  
        color: white;
        border-radius: 10px;
        font-size: 16px;
        height: 45px;
        width: 135px;
        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
        margin: 2px;  /* ë²„íŠ¼ ê°„ì˜ ê°„ê²© */
        margin-top: 27px; 
        padding: 0px 20px; 
    }

    .stButton button:hover {
        background-color: #F4834F;
        color: #f5c4b8; 
    }

    /* ë‘ ë²„íŠ¼ ê°„ ê°„ê²©ì„ ì¤„ì´ê¸° ìœ„í•´ ì¶”ê°€ */
    .stButton + .stButton {
        margin-left: 5px;  
    }

    /* ìŠ¤í¬ë¡¤ë°” ìƒ‰ìƒ */
    ::-webkit-scrollbar {
        width: 10px;
    }
    ::-webkit-scrollbar-track {
        background: #FFF8E1;
    }
    ::-webkit-scrollbar-thumb {
        background: #FF7043;
    }
    ::-webkit-scrollbar-thumb:hover {
        background: #E64A19;
    }
    </style>
    """, 
    unsafe_allow_html=True
)

st.markdown("<h1>ğŸ‘©â€ğŸ³ pAIk ì£¼ë¶€ ìš”ë¦¬ ë¹„ì„œ </h1>", unsafe_allow_html=True)

# ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰í•  ë•Œ ì´ ì‹¤í–‰íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ë””ë ‰í† ë¦¬ì— .env ë¼ëŠ” ì´ë¦„ì˜ íŒŒì¼ì„ ìƒì„±í•˜ì—¬ ChatGPT ì‚¬ìš©ì„ ìœ„í•œ API KEYì™€ ê°™ì€
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ì„ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.
# .env íŒŒì¼ ë‚´ìš©ì€ ì•„ë˜ì™€ ê°™ì´ ë¯¸ë¦¬ ì •ì˜í•´ ë‘ì–´ì•¼ í•©ë‹ˆë‹¤. 
# OPENAI_API_KEY="sk-proj-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"
#
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI API í‚¤ ë¡œë“œ
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()  # API í‚¤ê°€ ì—†ìœ¼ë©´ ë” ì´ìƒ ì‹¤í–‰ë˜ì§€ ì•Šë„ë¡ í•¨


# FAISS ë²¡í„° ìŠ¤í† ì–´ëŠ” 24-vectorstore-save.ipynbì—ì„œ ì €ì¥í•œ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
# ì´ íŒŒì¼ì´ ì¡´ì¬í•˜ê³  ìˆëŠ” ë””ë ‰í† ë¦¬ í•˜ìœ„ì— db/faiss ë””ë ‰í† ë¦¬ì— ë²¡í„° ìŠ¤í† ì–´ DB íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤

# FAISS ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹œ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ë©”ì‹œì§€ ìˆ˜ì •
def load_faiss():
    # ë¡œë”© ì¤‘ ë©”ì‹œì§€ë¥¼ ìœ„í•œ placeholder ìƒì„±
    loading_message = st.empty()
    
    # ë¡œë”© ì¤‘ ë©”ì‹œì§€ í‘œì‹œ
    loading_message.markdown('<div class="info-text">AI ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³  ìˆìŠµë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš” ğŸ˜Š</div>', unsafe_allow_html=True)
    
    # ì‹¤ì œ FAISS ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
    embeddings = OpenAIEmbeddings(openai_api_key=api_key)
    vector_store = FAISS.load_local('./db/faiss', OpenAIEmbeddings(), allow_dangerous_deserialization=True)

    # ë¡œë“œ ì™„ë£Œ í›„ ê¸°ì¡´ ë¡œë”© ë©”ì‹œì§€ë¥¼ ì„±ê³µ ë©”ì‹œì§€ë¡œ ë³€ê²½
    loading_message.markdown('<div class="info-text">AI ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!</div>', unsafe_allow_html=True)
    
    return vector_store

# Google Speech Recognitionì„ ì‚¬ìš©í•œ ìŒì„± ì¸ì‹ í•¨ìˆ˜
def recognize_speech():
    r = sr.Recognizer()
    
    # ë§ˆì´í¬ë¡œë¶€í„° ìŒì„± ì…ë ¥ ë°›ê¸°
    with sr.Microphone() as source:
        st.write("ìŒì„± ì¸ì‹ì¤‘.....")
        r.adjust_for_ambient_noise(source)  # ì£¼ë³€ ì†ŒìŒ ì¡°ì ˆ
        audio = r.listen(source)  # ìŒì„± ì…ë ¥ ë°›ê¸°
    
    try:
        # Google Speech Recognitionì„ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        text = r.recognize_google(audio, language='ko-KR')
        st.write("ì¸ì‹ ì™„ë£Œ")
        return text
    except sr.UnknownValueError:
        st.write("ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return ""
    except sr.RequestError as e:
        st.write(f"Google Speech Recognition ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""

# í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¬ìƒí•˜ëŠ” í•¨ìˆ˜ (gTTS ì‚¬ìš©)
def speak_text_gtts(text):
    try:
        # ìŒì„±ì„ gTTSë¡œ ë³€í™˜
        tts = gTTS(text=text, lang='ko')
        mp3_fp = BytesIO()
        tts.write_to_fp(mp3_fp)
        mp3_fp.seek(0)

        # ìŒì„±ì„ ë¸Œë¼ìš°ì €ì—ì„œ ì¬ìƒí•˜ê¸° ìœ„í•´ base64ë¡œ ì¸ì½”ë”©
        audio_data = base64.b64encode(mp3_fp.read()).decode("utf-8")
        audio_html = f'<audio autoplay="true" controls><source src="data:audio/mp3;base64,{audio_data}" type="audio/mp3"></audio>'
        
        st.markdown(audio_html, unsafe_allow_html=True)

    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
        st.error(f"ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ì±„íŒ… ë©”ì‹œì§€ë¥¼ session_stateì— ì €ì¥í•˜ì—¬ ë©”ëª¨ë¦¬ ê¸°ëŠ¥ êµ¬í˜„
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

# ì• ë‹ˆë©”ì´ì…˜ ìƒíƒœë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ session state í™•ì¸ ë° ì´ˆê¸°í™”
if "animation_finished" not in st.session_state:
    st.session_state["animation_finished"] = {}

# ì±„íŒ… ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ë§ (íƒ€ì´í•‘ ì• ë‹ˆë©”ì´ì…˜ ì ìš©)
def display_chat_message(role, message, index=None):
    # í•´ë‹¹ ë©”ì‹œì§€ì— ëŒ€í•´ ì• ë‹ˆë©”ì´ì…˜ì´ ì´ë¯¸ ëë‚¬ëŠ”ì§€ í™•ì¸
    message_key = hash(message)  # ë©”ì‹œì§€ì˜ í•´ì‹œ ê°’ì„ í‚¤ë¡œ ì‚¬ìš©

    if message_key not in st.session_state["animation_finished"]:
        # ë§í’ì„ ì„ ìœ„í•œ placeholder ìƒì„±
        bubble_placeholder = st.empty()  
        
        # íƒ€ì´í•‘ ì• ë‹ˆë©”ì´ì…˜ ì ìš©
        typing_animation(message, role, bubble_placeholder)
        
        # ì• ë‹ˆë©”ì´ì…˜ì´ ì™„ë£Œë˜ì—ˆìŒì„ ê¸°ë¡
        st.session_state["animation_finished"][message_key] = True
        
        # ì• ë‹ˆë©”ì´ì…˜ì´ ëë‚œ í›„ì—ë„ ë©”ì‹œì§€ë¥¼ ê³ ì •ì ìœ¼ë¡œ í‘œì‹œ
        bubble_placeholder.markdown(f'<div class="chat-bubble {role}-bubble">{message}</div>', unsafe_allow_html=True)
    else:
        # ì´ë¯¸ ì• ë‹ˆë©”ì´ì…˜ì´ ëë‚œ ë©”ì‹œì§€ëŠ” ê³ ì •ì ìœ¼ë¡œ í‘œì‹œ
        st.markdown(f'<div class="chat-bubble {role}-bubble">{message}</div>', unsafe_allow_html=True)

    # AIì˜ ê²½ìš° 'ë“£ê¸°' ë²„íŠ¼ ì¶”ê°€
    if role == "assistant" and index is not None:
        unique_key = f"listen_button_{index}_{hash(message)}"
        if st.button("ğŸ”Š ë“£ê¸°", key=unique_key):
            speak_text_gtts(message)

# íƒ€ì´í•‘ ì• ë‹ˆë©”ì´ì…˜ í•¨ìˆ˜
def typing_animation(message, role, bubble_placeholder, delay=0.05):
    displayed_text = ""
    for char in message:
        displayed_text += char
        bubble_placeholder.markdown(f'<div class="chat-bubble {role}-bubble">{displayed_text}</div>', unsafe_allow_html=True)
        time.sleep(delay)  # ê¸€ìê°€ í•œ ê¸€ìì”© ë‚˜íƒ€ë‚˜ëŠ” ë”œë ˆì´ ì ìš©

# ì±—ë´‡ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶œë ¥ í•¨ìˆ˜
def display_chat_history():
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    for i, entry in enumerate(st.session_state["chat_history"]):
        display_chat_message(entry["role"], entry["message"], index=i if entry["role"] == "assistant" else None)
    st.markdown('</div>', unsafe_allow_html=True)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜
def process_user_input(query, vector_store):
    if not query:
        st.markdown('<div class="warning-text">ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.</div>', unsafe_allow_html=True)
        return

    # ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ê°€
    if not any(entry['message'] == query and entry['role'] == "user" for entry in st.session_state["chat_history"]):
        st.session_state["chat_history"].append({"role": "user", "message": query})
        
    from langchain_core.prompts import PromptTemplate
    prompt = PromptTemplate.from_template(
        """ë‹¹ì‹ ì€ ì§ˆë¬¸-ë‹µë³€(Question-Answering)ì„ ìˆ˜í–‰í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
        ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ ë¬¸ë§¥(context) ì—ì„œ ì£¼ì–´ì§„ ì§ˆë¬¸(question) ì— ë‹µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
        ê²€ìƒ‰ëœ ë‹¤ìŒ ë¬¸ë§¥(context) ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸(question) ì— ë‹µí•˜ì„¸ìš”. 
        í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.

#Question:
{question}

#Context:
{context}

#Answer:"""
    )
    

    ###############
    # ë‹µë³€ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë ¤ì„œ í…ŒìŠ¤íŠ¸ì‹œ ì‚¬ìš©í•œ openapi
    from langchain.chat_models import ChatOpenAI 

    llm = ChatOpenAI(openai_api_key=api_key, temperature=0.5)
    retriever = vector_store.as_retriever()
    rag_chain = ({"context": retriever, "question": RunnablePassthrough()} | prompt | llm | StrOutputParser())
    result = rag_chain.invoke(query)
    ################


    # from langchain_community.chat_models import ChatOllama
    # from langchain_core.output_parsers import StrOutputParser

    # llm = ChatOllama(model="llama2:7b", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]))
    # retriever = vector_store.as_retriever()
    # rag_chain = ({"context": retriever, "question": RunnablePassthrough()} | prompt | llm | StrOutputParser())
    # result = rag_chain.invoke(query)

    # ì¤‘ë³µëœ ë‹µë³€ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸ í›„ ì¶”ê°€
    if not any(entry['message'] == result and entry['role'] == "assistant" for entry in st.session_state["chat_history"]):
        st.session_state["chat_history"].append({"role": "assistant", "message": result})


# ë²¡í„° ìŠ¤í† ì–´ ì„¤ì •
vector_store = load_faiss()

st.markdown('<div class="question-text">ì €ëŠ” ìš”ë¦¬ë¥¼ ë„ì™€ ë“œë¦¬ëŠ” ìš”ë¦¬ì‚¬ ë¹„ì„œì…ë‹ˆë‹¤.</div>', unsafe_allow_html=True)

st.markdown('<div class="question-text">ê¶ê¸ˆí•œ ìš”ë¦¬ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”.</div>', unsafe_allow_html=True)

# ì…ë ¥ì°½ê³¼ ë²„íŠ¼ì„ ë‚˜ë€íˆ ë°°ì¹˜
col1, col2, col3 = st.columns([3, 1, 1])  

with col1:
    user_input = st.text_input("")

with col2:
    submit_button = st.button("ì§ˆë¬¸ í•˜ê¸°")

with col3:
    speech_button = st.button("ğŸ¤ ìŒì„± ì§ˆë¬¸")

# ë²„íŠ¼ ë™ì‘ ì²˜ë¦¬
if submit_button:
    process_user_input(user_input, vector_store)

if speech_button:
    user_input = recognize_speech()
    if user_input:
        process_user_input(user_input, vector_store)

# ì±—ë´‡ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
display_chat_history()